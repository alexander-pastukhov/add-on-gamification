---
title: "Gamification Analysis"
author: "Alexander (Sasha) Pastukhov"
date: "11 Juli 2018"
output:
  word_document: default
  html_document:
    highlight: tango
    theme: united
  pdf_document: default
  github_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, message=FALSE, warning=FALSE}
suppressMessages(library('tidyverse'))
library('fs')
library('knitr')
library('lme4')
library('lmerTest')
library('BayesFactor')
library('psycho')
library('coin')
library('car')
library('lmPerm')
library('boot')
library('psych')
library("sjstats")
```

# Loading and preprocessing the data

```{r Loading}
rm(list= ls())

results <-
  tibble(filename= dir_ls(path= "Data", type= "file", regexp = 'csv$')) %>%
  rowwise() %>%
  do(read_csv2(.$filename, 
               locale = locale(decimal_mark = ","),
               col_types = cols(Observer = col_character(),
                                Condition = col_character(),
                                SessionID = col_character(),
                                Block = col_double(),
                                Trial = col_double(),
                                COA = col_double(),
                                Color0 = col_double(),
                                Color1 = col_double(),
                                Color2 = col_double(),
                                Color3 = col_double(),
                                Target = col_character(),
                                Which = col_double(),
                                Match = col_logical(),
                                FlipComplimentary = col_logical(),
                                Response = col_logical(),
                                RT = col_double(),
                                Correct = col_logical(),
                                OnsetDelay = col_double()))) %>%

  # converting selected variables to factors and using meaningful labels instead of boolean balues
  ungroup() %>%
  mutate(Target= as.factor(Target),
        Condition= as.factor(Condition),
        Observer= as.factor(Observer),
        
        Match= ifelse(Match, 'match', 'mismatch'), 
        Response= ifelse(Response, 'match', 'mismatch'), 
        Correct= Match == Response)

# adding block index within the COA
results <- results %>%
  group_by(Observer, Condition, COA, Block) %>%
  summarise() %>%
  
  group_by(Observer, Condition, COA) %>%
  mutate(coaBlockIndex= 1:n()) %>%

  right_join(results, by= c('Observer', 'Condition', 'COA', 'Block')) %>%

    # retain only 12 blocks to facilitate comparison (some observers had more blocks)
  filter(Block <= 12)
```

Computing score for each trial, including the _experiment_ condition group. Later, this would show whether having a maximal score in mind alters your behavior. For each trial the score is calculated as $$S(t)= Combo(t) \times \frac{ 10 \times (4-RT(t))}{3}$$/, where _RT(t)_ is the response time and _Combo(t)_ is a combo multiplier. The latter is increased by 1 after every correct answer but is reset to 1 after a mistake. 

```{r Compute score}

#' Computing score based on the time-based score and combo (history)
#'
#' @param timebased_score vector of float, response time-based score for the current trial
#'
#' @return vector of floats, combo-based score
compute_score_within_block <- function(timebased_score){
  
  combo <- 1
  score <- rep(NA, length(timebased_score))
  for(iTrial in 1:length(timebased_score)){
    if (timebased_score[iTrial]>=0){
      score[iTrial] <- timebased_score[iTrial] * combo
      combo <- combo + 1
    }
    else{
      score[iTrial] <- 0
      combo <- 1
    }
  }
  
  score
}


# computing time-based score, maximum is 10, but time penalty applies
# this value will be translated into the real score later, based on combo and response
results <- results %>%
  # computing the time-based score the way it was done in the game
  mutate(timebased_score= ceiling(10*((4-RT)/3))) %>%
         
  # clamping the score within 0..10 range, -1 means that the response was incorrect
  mutate(timebased_score= ifelse(timebased_score>10, 10, timebased_score),
         timebased_score= ifelse(timebased_score<0, 0, timebased_score), 
         timebased_score= ifelse(!Correct, -1, timebased_score)) %>%

  group_by(Observer, Condition, COA, Block) %>%
  mutate(score= compute_score_within_block(timebased_score)) %>%
  ungroup()

rm('compute_score_within_block')
```


# Comparing two experimental groups to see if having add-on gamification changes behaviors

## Effect of the cue-onset asynchrony (COA) and experimental condition on _performance_
```{r Function to bootstrap CI for group means}
#' Computes mean value for the sample
#'
#' @description Computes mean value for the \code{variableOfInterest} using a sample of row, 
#'  defined by \code{bootstrapIndex}, from the \code{variableOfInterest}. 
#' @param irrelevantData fake data supplied to \code{boot} function those length is equal to the total 
#' number of rows for a single observer 
#' @param bootstrapIndex index of rows supplied by \code{boot} function.
#' @param dfOfInterest table with actual group data
#' @param variableOfInterest name of the column that must be sampled
#' @param avgFun function used for computing average value
#'
#' @return sampled group mean 
getVariableSampleMean <- function(irrelevantData, bootstrapIndex, dfOfInterest, variableOfInterest, avgFun){
  dfOfInterest %>%
    # first sampling each observer the same way and computing their averages
    group_by(Observer) %>%
    slice(bootstrapIndex) %>%
    summarise(varMean= avgFun(!!as.name(variableOfInterest), na.rm= TRUE)) %>%
  
    # then, the group average
    ungroup() %>%
    summarise(varMean= mean(varMean)) %>%
    
    # returning only the group mean
    pull(varMean)
}

#' Computes variable mean and 95% bootstrapped bca CI 
#'
#' @param data data table
#' @param variableOfInterest name of the column to analyze
#' @param seed seed for the random numbers generator (to make CIs reproducable). NULL means no seeding
#' @param avgFun function used for computing average value, defaults to 'mean'
#' @param R number of bootstrap iterations, defaults to 2000
#'
#' @return table with columns bcaLower, meanValue, bcaUpper
getvariableCI <- function(data, variableOfInterest, seed= NULL, avgFun= mean, R= 2000){
  # figuring out number of trials per observer
  trialN <- data %>%
    group_by(Observer) %>%
    summarise(trialCount= n()) %>%
    pull(trialCount)
  
  # seeding the random numbers generator
  if (!is.null(seed)){
    set.seed(seed)
  }
  
  # sample mean
  sampledMean <-boot(data= 1:max(trialN), 
                     statistic = getVariableSampleMean, R= R, 
                     dfOfInterest= data, 
                     variableOfInterest= variableOfInterest, 
                     avgFun= avgFun)
  
  # compute CIs
  sampledCI <- boot.ci(boot.out= sampledMean, type= 'bca')
  
  # compute mean over ALL the data
  meanValue <- getVariableSampleMean(NULL, 1:max(trialN), data, variableOfInterest, avgFun)
  
  # package for output
  data.frame(bcaLower= sampledCI$bca[4], meanValue= meanValue, bcaUpper= sampledCI$bca[5])
}
```


```{r, Group Performance, cache=TRUE}
groupPerformance <- results %>%
  group_by(Condition, COA, coaBlockIndex) %>%
  do(getvariableCI(data= ., variableOfInterest = 'Correct', seed = 1538985527))
```

```{r}
test_measure <- function(df){
  # frequentist ANOVA
  anova_performance <- aov(value ~ coaBlockIndex * COA * Condition, data= df)
  anova_table <- 
    data.frame(head(summary(anova_performance)[[1]], -1)) %>%
    rownames_to_column("factor")
  
  lm_table <- data.frame(summary.lm(anova_performance)$coefficients[-1, ])
  anova_table$t <- lm_table$t.value
    
  anova_table$cohens_f <- cohens_f(anova_performance)$cohens.f
  
  
  perm_performance <- aovp(value ~ coaBlockIndex * COA * Condition, data= df)
  perm_table <- 
    data.frame(head(summary(perm_performance)[[1]], -1)) %>%
    rownames_to_column("factor") %>%
    select(-Df)
  
  left_join(anova_table, perm_table, by="factor")
}
```

```{r}
ggplot(data= groupPerformance, 
       aes(x= coaBlockIndex, y= meanValue, ymin= bcaLower, ymax= bcaUpper,
           color= Condition, linetype= Condition)) + 
  geom_errorbar(width= 0.3, linetype= 'solid')+
  geom_line() +
  geom_point(aes(shape= Condition), size= 3) +
  # geom_point(position = position_jitter(width= 0.2), color= 'black') +
  facet_grid(.~COA) +
  ylab('Performance [%]') +
  xlab('Block index') +
  theme(panel.grid.minor.x = element_blank(), legend.position = "none")

ggsave("performance.pdf", width = 12, height = 8, units = 'cm', useDingbats = FALSE)

```

Performance: ANOVA
```{r, Performance - frequentist ANOVA}
set.seed(557046)
results %>%
  group_by(Observer, Condition, COA, coaBlockIndex) %>%
  summarise(Performance= 100 * mean(Correct), 
            logitPerformance= car::logit(Performance, percents = TRUE, adjust = 0.025), 
            value = logitPerformance) %>%
  test_measure(.) %>% 
  select(factor, Df, F.value, t, Pr..F., Pr.Prob., cohens_f) %>%
  kable(digits= c(0, 0, 1, 1, 4, 4,  2), 
        col.names = c("Factor", "Df", "F", "t", "p(F)", "p(Perm)", "Cohen’s ƒ2"))
```

## Effect of the cue-onset asynchrony (COA) and experimental condition on _response times_

```{r, group RT, cache= TRUE}
groupMedianRT <- results %>%
  group_by(Condition, COA, coaBlockIndex) %>%
  do(getvariableCI(data= ., variableOfInterest = 'RT', seed = 1538988495, avgFun = median))
```

```{r}
ggplot(data= groupMedianRT, 
       aes(x= coaBlockIndex, y= meanValue, ymin= bcaLower, ymax= bcaUpper,
           color= Condition, linetype= Condition)) + 
  geom_errorbar(width= 0.3, linetype= 'solid')+
  geom_line() +
  geom_point(aes(shape= Condition), size= 3) +
  # geom_point(position = position_jitter(width= 0.2), color= 'black') +
  facet_grid(.~COA) +
  ylab('Median RT [s]') +
  xlab('Block index') +
  theme(panel.grid.minor.x = element_blank(), legend.position = "none")

ggsave('RT.pdf', width = 12, height = 8, units = 'cm', useDingbats = FALSE)
```

RT: ANOVA
```{r RT - frequentist ANOVA}
set.seed(450444)
results %>%
  group_by(Observer, Condition, COA, coaBlockIndex) %>%
  summarise(RT= median(RT), 
            value = RT) %>%
  test_measure(.) %>%
  select(factor, Df, F.value, t, Pr..F., Pr.Prob., cohens_f) %>%
  kable(digits= c(0, 0, 1, 1, 4, 4,  2), 
        col.names = c("Factor", "Df", "F", "t", "p(F)", "p(Perm)", "Cohen’s ƒ2"))
```

## Effect of the cue-onset asynchrony (COA) and experimental condition on _total score_
```{r, Score, cache= TRUE}
groupScore <- results %>%
  group_by(Condition, COA, coaBlockIndex) %>%
  do(getvariableCI(data= ., variableOfInterest = 'score', seed = 1538989294))
```

```{r}
ggplot(data= groupScore, 
       aes(x= coaBlockIndex, y= meanValue, ymin= bcaLower, ymax= bcaUpper,
           color= Condition, linetype= Condition)) + 
  geom_errorbar(width= 0.3, linetype= 'solid')+
  geom_line() +
  geom_point(aes(shape= Condition), size= 3) +
  # geom_point(position = position_jitter(width= 0.2), color= 'black') +
  facet_grid(.~COA) +
  ylab('Score [thousands of points]') +
  xlab('Block index') +
  theme(panel.grid.minor.x = element_blank(), legend.position = "none")
ggsave('score.pdf', width = 12, height = 8, units = 'cm', useDingbats = FALSE)
```


**Score: Frequentist and permutation ANOVA**
```{r Score - frequentist ANOVA}
set.seed(270453)
results %>%
  group_by(Observer, Condition, COA, coaBlockIndex) %>%
  summarise(`Block Score`= sum(score), 
            value = `Block Score`) %>%
  test_measure(.) %>%
  select(factor, Df, F.value, t, Pr..F., Pr.Prob., cohens_f) %>%
  kable(digits= c(0, 0, 1, 1, 4, 4,  2), 
        col.names = c("Factor", "Df", "F", "t", "p(F)", "p(Perm)", "Cohen’s ƒ2"))
```



# Post-study questionnaires

``` {r, Load and preprocess questionnaires}
questionnaire <- suppressMessages(read_csv2(file.path('Questionnaire', 'Questionnaire_ErsteTestung_ohneIFN.csv'))) %>%
  ungroup() %>%
  mutate(Condition= as.factor(Condition), 
         Condition= fct_recode(Condition, game= '1', experiment= '2'), 
         Condition= fct_relevel(Condition, 'experiment'))
```

## Gamer/Non-gamer

This questionnaire is important to check the balance between the two experimental groups

```{r, Gamer}
gamer <- questionnaire %>%
  mutate(d_nonGamer= sqrt((GP01_01-2.58)^2+(GP02_01-1.61)^2+
                     (GP02_02-1.88)^2+(GP02_03-4.3)^2+
                     (GP02_04-1.49)^2+(GP02_05-2.69)^2+
                     (GP02_06-2.20)^2+(GP02_07-2.59)^2+
                     (GP02_08-4.68)^2+(GP02_09-2.20)^2)) %>%
  select(Observer, Condition, d_nonGamer)

oneway_test(d_nonGamer ~ Condition, gamer)
ttestBF(formula= d_nonGamer ~ Condition, data= data.frame(gamer))


gamer_plot <- gamer %>% ggplot(aes(x= Condition, y= d_nonGamer, color= Condition)) +
  geom_boxplot(outlier.shape = NA) + 
  geom_point(position = position_dodge2(width= 0.05), color= 'black') + 
  ylab("Distance to non-gamers' cluster") + 
  theme(panel.grid.major.x = element_blank(), legend.position = "none")
print(gamer_plot)

# ggsave("gamer.pdf", gamer_plot, width = 6, height)

# rm(gamer, gamer_plot)
```



```{r}
gaming_alpha <- psych::alpha(questionnaire %>% select(starts_with('GP')) %>% select(-GP03_01))
```
Internal consistency for Gamer/Non-gamer questionnaire is `r gaming_alpha$total$std.alpha`.

```{r}
rm(gaming_alpha)
```

## Intrinsic Motivation
```{r, IM}
# computing subscales for the Intrinsic Motivation
IM <- questionnaire %>%
  mutate(enjoyment =  ((IM01_01 + IM01_05 + IM01_08 + IM01_10 + IM01_14 + IM01_17 + IM01_20)/7),
         competence = ((IM01_04 + IM01_07 + IM01_12 + IM01_16 + IM01_22)/5),
         choice = ((IM01_03 + IM01_11 + IM01_15 + IM01_19 + IM01_21)/5),
         pressure =((IM01_02 + IM01_06 + IM01_09 + IM01_13 + IM01_18)/5)) %>%
  
  select(Observer, Condition, enjoyment, competence, choice, pressure) %>%
  gather(key= "Subscale", value = "Response", -Observer, -Condition)

t_tests <- function(subscaleDF){
  test_results <- oneway_test(Response ~ Condition, data= subscaleDF)
  
  bf_results <- extractBF(ttestBF(formula= Response ~ Condition, data= data.frame(subscaleDF)))
  
  
  tibble(Subscale= subscaleDF$Subscale[1], BF= bf_results$bf, `BF error`= bf_results$error, Z= statistic(test_results), pvalue= pvalue(test_results))
}

# Fisher-Pitman permutation test on each subscale, multiple comparions adjustment via Holm's method 
IM %>% 
  group_by(Subscale) %>%
  do(t_tests(.)) %>%
  ungroup() %>%
  mutate(`p(adjusted)`= p.adjust(pvalue, method = 'holm')) %>%
  kable(.)

IM_plot <- IM %>% ggplot(aes(x= Condition, y= Response, color= Condition)) +
  geom_boxplot(outlier.shape = NA) + 
  geom_point(position = position_dodge2(width = 0.15), color= 'black') + 
  facet_grid(. ~ Subscale) + 
  theme(panel.grid.major.x = element_blank(), legend.position = "none")

print(IM_plot)
ggsave("IM.pdf", width = 14, height = 8, units = 'cm', useDingbats = FALSE)

# rm('oneway_permutation_test', IM, IM_plot)
```
Internal consistency
```{r}
consistency_IM <- tibble(scale= c('choice', 'competence', 'enjoyment', 'pressure'), alpha= NA)
consistency_IM$alpha[1]= psych::alpha(questionnaire[, c("IM01_03", "IM01_11", "IM01_15", "IM01_19", "IM01_21")])$total$std.alpha
consistency_IM$alpha[2]= psych::alpha(questionnaire[, c("IM01_04", "IM01_07", "IM01_12", "IM01_16", "IM01_22")])$total$std.alpha
consistency_IM$alpha[3]= psych::alpha(questionnaire[, c("IM01_01", "IM01_05", "IM01_08", "IM01_10", "IM01_14", "IM01_17", "IM01_20")])$total$std.alpha
consistency_IM$alpha[4]= psych::alpha(questionnaire[, c("IM01_02", "IM01_06", "IM01_09", "IM01_13", "IM01_18")])$total$std.alpha
kable(consistency_IM, col.names= c("Scale", " Cronbach's alpha"), digits = c(0, 2))
```