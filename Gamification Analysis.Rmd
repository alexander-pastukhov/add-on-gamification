---
title: "Gamification Analysis"
author: "Alexander (Sasha) Pastukhov"
date: "11 Juli 2018"
output:
  word_document: default
  html_document:
    highlight: tango
    theme: united
  pdf_document: default
  github_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, message=FALSE, warning=FALSE}
library(boot)
library(brms)
library(fs)
library(ggbeeswarm)
library(knitr)
library(psycho)
library(tidyverse)
```

```{r Tabula rasa}
rm(list= ls())
```

## Utility functions

### Summarizies a brms model via drop-one method 
```{r model summary}
summarize_models <- function(brm_model, 
                             terms = c("Condition", "COA", "coaBlockIndex", "d_nonGamer", "Condition:coaBlockIndex")){

  # reduced models, taking out one term at a time
  reduced_models <- purrr::map(terms, ~update(brm_model, formula. = as.formula(stringr::str_c("~ . - ", .)),  cores = future::availableCores()))
  names(reduced_models) <- terms
  
  brm_model <- brms::add_criterion(brm_model, "loo", reloo=TRUE)
  reduced_models <- purrr::map(reduced_models, ~brms::add_criterion(., "loo", , reloo=TRUE))
  
  comparison_with_the_full_model_loo <- purrr::map(reduced_models, ~brms::loo_compare(brm_model, .))
  model_weight_via_loo <- purrr::map(reduced_models, ~brms::loo_model_weights(brm_model, .))
  
  
  loos <-
    purrr::map2(comparison_with_the_full_model_loo, 
              names(comparison_with_the_full_model_loo), 
              ~broom.mixed::tidy(.x) %>% 
                rename(term = .rownames) %>%
                mutate(elpd_diff = ifelse(term!=".", -elpd_diff, elpd_diff)) %>%
                filter(elpd_diff != 0) %>%
                mutate(term = .y)) %>%
    bind_rows() %>%
    mutate_if(is.numeric, round, digits=2) %>%
    mutate(dLOO= stringr::str_c(elpd_diff, "Â±", se_diff)) %>%
    select(term, dLOO)
  
  weights <-
    purrr::map2(model_weight_via_loo, 
                names(model_weight_via_loo),
               ~c(.x)[2]) %>%
                bind_rows() %>%
                t() %>%
                data.frame() %>%
                tibble::rownames_to_column("term") %>%
                dplyr::rename(weight=2) %>%
                mutate(weight = round(weight, 2))

  brms_summary <- 
    broom.mixed::tidy(brm_model) %>%
    filter(effect == "fixed", term!="(Intercept)") %>%
    select(-component, -group, - effect) %>%
    mutate(term = stringr::str_replace_all(term, c("Conditiongame"="Condition"))) %>%
    left_join(loos, by="term") %>%
    left_join(weights, by="term") %>%
    mutate(term = stringr::str_replace_all(term, "Conditiongame", "Condition")) %>%
    mutate_if(is.numeric, round, digits=2) %>%
    mutate(CI = glue::glue("{conf.low}..{conf.high}")) %>%
    select(term, estimate, CI, dLOO, weight)

  brms_summary
}
```

## Loading and preprocessing the data

```{r Loading}
results <-
  tibble(filename= fs::dir_ls(path= "Data", type= "file", regexp = 'csv$')) %>%
  rowwise() %>%
  do(read_csv2(.$filename, 
               locale = locale(decimal_mark = ","),
               col_types = cols(Observer = col_character(),
                                Condition = col_character(),
                                SessionID = col_character(),
                                Block = col_double(),
                                Trial = col_double(),
                                COA = col_double(),
                                Color0 = col_double(),
                                Color1 = col_double(),
                                Color2 = col_double(),
                                Color3 = col_double(),
                                Target = col_character(),
                                Which = col_double(),
                                Match = col_logical(),
                                FlipComplimentary = col_logical(),
                                Response = col_logical(),
                                RT = col_double(),
                                Correct = col_logical(),
                                OnsetDelay = col_double()))) %>%

  # converting selected variables to factors and using meaningful labels instead of boolean balues
  ungroup() %>%
  mutate(Target= as.factor(Target),
         Match= ifelse(Match, 'match', 'mismatch'), 
         Response= ifelse(Response, 'match', 'mismatch'), 
         Correct= Match == Response)

# adding block index within the COA
results <- results %>%
  group_by(Observer, Condition, COA, Block) %>%
  summarise() %>%
  
  group_by(Observer, Condition, COA) %>%
  mutate(coaBlockIndex= 1:n()) %>%

  right_join(results, by= c('Observer', 'Condition', 'COA', 'Block')) %>%

    # retain only 12 blocks to facilitate comparison (some observers had more blocks)
  filter(Block <= 12)
```

Computing score for each trial, including the _experiment_ condition group. Later, this would show whether having a maximal score in mind alters your behavior. For each trial the score is calculated as $$S(t)= Combo(t) \times \frac{ 10 \times (4-RT(t))}{3}$$/, where _RT(t)_ is the response time and _Combo(t)_ is a combo multiplier. The latter is increased by 1 after every correct answer but is reset to 1 after a mistake. 

```{r Compute score}

#' Computing score based on the time-based score and combo (history)
#'
#' @param timebased_score vector of float, response time-based score for the current trial
#'
#' @return vector of floats, combo-based score
compute_score_within_block <- function(timebased_score){
  
  combo <- 1
  score <- rep(NA, length(timebased_score))
  for(iTrial in 1:length(timebased_score)){
    if (timebased_score[iTrial]>=0){
      score[iTrial] <- timebased_score[iTrial] * combo
      combo <- combo + 1
    }
    else{
      score[iTrial] <- 0
      combo <- 1
    }
  }
  
  score
}


# computing time-based score, maximum is 10, but time penalty applies
# this value will be translated into the real score later, based on combo and response
results <- results %>%
  # computing the time-based score the way it was done in the game
  mutate(timebased_score= ceiling(10*((4-RT)/3))) %>%
         
  # clamping the score within 0..10 range, -1 means that the response was incorrect
  mutate(timebased_score= ifelse(timebased_score>10, 10, timebased_score),
         timebased_score= ifelse(timebased_score<0, 0, timebased_score), 
         timebased_score= ifelse(!Correct, -1, timebased_score)) %>%

  group_by(Observer, Condition, COA, Block) %>%
  mutate(score= compute_score_within_block(timebased_score)) %>%
  ungroup()

rm('compute_score_within_block')
```

# Post-study questionnaires

``` {r, Load and preprocess questionnaires}
questionnaire <- suppressMessages(read_csv2(file.path('Questionnaire', 'Questionnaire_ErsteTestung_ohneIFN.csv'))) %>%
  ungroup() %>%
  mutate(Condition= as.factor(Condition), 
         Condition= fct_recode(Condition, game= '1', experiment= '2'), 
         Condition= fct_relevel(Condition, 'experiment'))
```

## Gamer habits
This questionnaire is important to check the balance between the two experimental groups

```{r, Gamer}
gamer <- 
  questionnaire %>%
  mutate(d_nonGamer= sqrt((GP01_01-2.58)^2+
                          (GP02_01-1.61)^2+
                          (GP02_02-1.88)^2+
                          (GP02_03-4.3)^2+
                          (GP02_04-1.49)^2+
                          (GP02_05-2.69)^2+
                          (GP02_06-2.20)^2+
                          (GP02_07-2.59)^2+
                          (GP02_08-4.68)^2+
                          (GP02_09-2.20)^2)) %>%
  select(Observer, Condition, d_nonGamer)

# adding gaming preference to results
results <- 
  results %>%
  left_join(gamer %>% mutate(Condition = as.character(Condition)), by=c("Observer", "Condition")) %>%
  ungroup() %>%
  mutate(Condition= as.factor(Condition),
         Observer= as.factor(Observer))

```


Plots and formal analysis

```{r}
gamer_cohen_d <- psych::cohen.d(gamer$d_nonGamer, gamer$Condition)
gaming_alpha <- psych::alpha(questionnaire %>% select(starts_with('GP')) %>% select(-GP03_01))

gamer_brms <- brms::brm(d_nonGamer ~ Condition,
                        data=gamer,
                        save_all_pars = TRUE,
                        cores=future::availableCores())
gamer_brms<- brms::add_criterion(gamer_brms, "loo")

gamer_intercept_brms <- brms::brm(d_nonGamer ~ 1,
                                  data=gamer,
                                  save_all_pars = TRUE,
                                  cores=future::availableCores())
gamer_intercept_brms <- brms::add_criterion(gamer_intercept_brms, "loo")

brms::loo_compare(gamer_brms, gamer_intercept_brms)
brms::loo_model_weights(gamer_brms, gamer_intercept_brms)

ggplot(gamer, 
       aes(x= Condition, y= d_nonGamer, color= Condition)) +
  geom_boxplot(outlier.shape = NA) + 
  geom_quasirandom(width= 0.05, color= 'black', method="tukeyDense") + 
  ylab("Distance to non-gamers' cluster") + 
  theme(panel.grid.major.x = element_blank(), legend.position = "none")
```

## Intrinsic Motivation
```{r IM}
# computing subscales for the Intrinsic Motivation
 qsubscale <- tibble(subscale = c("enjoyment", "competence", "choice", "pressure"),
                     questions = list(c("IM01_01", "IM01_05", "IM01_08", "IM01_10", "IM01_14", "IM01_17", "IM01_20"),
                                      c("IM01_04", "IM01_07", "IM01_12", "IM01_16", "IM01_22"),
                                      c("IM01_03", "IM01_11", "IM01_15", "IM01_19", "IM01_21"),
                                      c("IM01_02", "IM01_06", "IM01_09", "IM01_13", "IM01_18")))

qsubscale <- 
  qsubscale %>%
  group_by(subscale) %>%
  mutate(responses =  purrr::map2(subscale, questions, 
                                 ~questionnaire %>%
                                  dplyr::select_at(c("Condition", "Observer", .y)))) %>%
  mutate(responses = purrr::map(responses, ~tidyr::pivot_longer(., cols=-one_of(c("Condition", "Observer")),
                                                                names_to = "Question", values_to = "Response"))) %>%
  mutate(responses = purrr::map(responses, ~left_join(., 
                                                      gamer %>% mutate(Condition = as.character(Condition)), 
                                                      by=c("Observer", "Condition"))))



# full model
set.seed(2323357)
qsubscale <- 
  qsubscale %>%
  mutate(brms_fit = purrr::map(responses, ~brms::brm(Response ~ Condition + d_nonGamer + (1|Observer), 
                                                     brms::cumulative("logit"),
                                                     data=.,
                                                     cores=future::availableCores())))

qsubscale <- 
  qsubscale %>%
  mutate(ModelSummary = purrr::map(brms_fit, ~summarize_models(., terms = c("Condition", "d_nonGamer"))))


qsubscale %>%
  mutate(ModelSummary = purrr::map(ModelSummary, ~mutate(., CI = as.character(CI)))) %>%
  dplyr::select(subscale, ModelSummary) %>%
  tidyr::unnest(ModelSummary) %>%
  na.omit() %>%
  select(-ps) %>%
  arrange(subscale)
```

  
```{r}

IM <-
  qsubscale %>%
  select(subscale, responses) %>%
  unnest(responses) %>%
  rename(Subscale = subscale) %>%
  group_by(Subscale, Condition, Observer) %>%
  summarise(Response = mean(Response))


ggplot(IM, aes(x= Condition, y= Response, color= Condition)) +
  geom_boxplot(outlier.shape = NA) + 
  ggbeeswarm::geom_quasirandom(color= 'black', width=0.2) + 
  facet_grid(. ~ Subscale) + 
  theme(panel.grid.major.x = element_blank(), legend.position = "none")

ggsave("IM.pdf", width = 14, height = 8, units = 'cm', useDingbats = FALSE)

```
Internal consistency
```{r}
consistency_IM <- tibble(scale= c('choice', 'competence', 'enjoyment', 'pressure'), alpha= NA)
consistency_IM$alpha[1]= psych::alpha(questionnaire[, c("IM01_03", "IM01_11", "IM01_15", "IM01_19", "IM01_21")])$total$std.alpha
consistency_IM$alpha[2]= psych::alpha(questionnaire[, c("IM01_04", "IM01_07", "IM01_12", "IM01_16", "IM01_22")])$total$std.alpha
consistency_IM$alpha[3]= psych::alpha(questionnaire[, c("IM01_01", "IM01_05", "IM01_08", "IM01_10", "IM01_14", "IM01_17", "IM01_20")])$total$std.alpha
consistency_IM$alpha[4]= psych::alpha(questionnaire[, c("IM01_02", "IM01_06", "IM01_09", "IM01_13", "IM01_18")])$total$std.alpha
kable(consistency_IM, col.names= c("Scale", " Cronbach's alpha"), digits = c(0, 2))
```


# Comparing two experimental groups to see if having add-on gamification changes behaviors

## Effect of the cue-onset asynchrony (COA) and experimental condition on _performance_
```{r Function to bootstrap CI for group means}
#' Computes mean value for the sample
#'
#' @description Computes mean value for the \code{variableOfInterest} using a sample of row, 
#'  defined by \code{bootstrapIndex}, from the \code{variableOfInterest}. 
#' @param irrelevantData fake data supplied to \code{boot} function those length is equal to the total 
#' number of rows for a single observer 
#' @param bootstrapIndex index of rows supplied by \code{boot} function.
#' @param dfOfInterest table with actual group data
#' @param variableOfInterest name of the column that must be sampled
#' @param avgFun function used for computing average value
#'
#' @return sampled group mean 
getVariableSampleMean <- function(irrelevantData, bootstrapIndex, dfOfInterest, variableOfInterest, avgFun){
  dfOfInterest %>%
    # first sampling each observer the same way and computing their averages
    group_by(Observer) %>%
    slice(bootstrapIndex) %>%
    summarise(varMean= avgFun(!!as.name(variableOfInterest), na.rm= TRUE)) %>%
  
    # then, the group average
    ungroup() %>%
    summarise(varMean= mean(varMean)) %>%
    
    # returning only the group mean
    pull(varMean)
}

#' Computes variable mean and 95% bootstrapped bca CI 
#'
#' @param data data table
#' @param variableOfInterest name of the column to analyze
#' @param seed seed for the random numbers generator (to make CIs reproducable). NULL means no seeding
#' @param avgFun function used for computing average value, defaults to 'mean'
#' @param R number of bootstrap iterations, defaults to 2000
#'
#' @return table with columns bcaLower, meanValue, bcaUpper
getvariableCI <- function(data, variableOfInterest, seed= NULL, avgFun= mean, R= 2000){
  # figuring out number of trials per observer
  trialN <- data %>%
    group_by(Observer) %>%
    summarise(trialCount= n()) %>%
    pull(trialCount)
  
  # seeding the random numbers generator
  if (!is.null(seed)){
    set.seed(seed)
  }
  
  # sample mean
  sampledMean <-boot(data= 1:max(trialN), 
                     statistic = getVariableSampleMean, R= R, 
                     dfOfInterest= data, 
                     variableOfInterest= variableOfInterest, 
                     avgFun= avgFun)
  
  # compute CIs
  sampledCI <- boot.ci(boot.out= sampledMean, type= 'bca')
  
  # compute mean over ALL the data
  meanValue <- getVariableSampleMean(NULL, 1:max(trialN), data, variableOfInterest, avgFun)
  
  # package for output
  data.frame(bcaLower= sampledCI$bca[4], meanValue= meanValue, bcaUpper= sampledCI$bca[5])
}
```


```{r, Group Performance, cache=TRUE}
groupPerformance <- results %>%
  group_by(Condition, COA, coaBlockIndex) %>%
  do(getvariableCI(data= ., variableOfInterest = 'Correct', seed = 1538985527))
```


```{r}
ggplot(data= groupPerformance, 
       aes(x= coaBlockIndex, y= meanValue, ymin= bcaLower, ymax= bcaUpper,
           color= Condition, linetype= Condition)) + 
  geom_errorbar(width= 0.3, linetype= 'solid')+
  geom_line() +
  geom_point(aes(shape= Condition), size= 3) +
  # geom_point(position = position_jitter(width= 0.2), color= 'black') +
  facet_grid(.~COA) +
  ylab('Accuracy [%]') +
  xlab('Block index') +
  theme(panel.grid.minor.x = element_blank(), legend.position = "none")

ggsave("performance.pdf", width = 12, height = 8, units = 'cm', useDingbats = FALSE)

```


```{r accuracy analysis}
accuracy <- 
  results %>%
  group_by(Observer, Condition, COA, coaBlockIndex, d_nonGamer) %>%
  summarise(CorrectN= sum(Correct),
            TotalN = n(),
            CorrectP = CorrectN/TotalN) %>%
  ungroup() %>%
  mutate(COA = COA / 1000)

accuracy_brm <- 
  brms::brm(CorrectN  | trials(TotalN) ~ Condition + COA + coaBlockIndex + d_nonGamer + Condition:coaBlockIndex + (1|Observer),
            data=accuracy,
            family = "binomial",
            cores = future::availableCores())

summarize_models(accuracy_brm)
```

## Effect of the cue-onset asynchrony (COA) and experimental condition on _sensitivity_

```{r sensitivity}
sensitivity_per_observer <-
  results %>%
  group_by(Observer, Condition, COA, coaBlockIndex, d_nonGamer) %>%
  summarise(n_hit = sum(Match=="match" & Response=="match"), 
            n_fa = sum(Match=="mismatch" & Response=="match"), 
            n_miss = sum(Match=="match" & Response=="mismatch"),
            n_cr = sum(Match=="mismatch" & Response=="mismatch"), 
            dprime = dprime(n_hit, n_fa, n_miss, n_cr)$dprime) %>%
  ungroup() %>%
  mutate(COA = COA / 1000)


groupSensitivity <-
  sensitivity_per_observer %>%
  group_by(Condition, COA, coaBlockIndex) %>%
  summarise(meanValue = mean(dprime))

ggplot(data= groupSensitivity, 
       aes(x= coaBlockIndex, y= meanValue, #ymin= bcaLower, ymax= bcaUpper,
           color= Condition, linetype= Condition)) + 
  # geom_errorbar(width= 0.3, linetype= 'solid')+
  geom_line() +
  geom_point(aes(shape= Condition), size= 3) +
  # geom_point(position = position_jitter(width= 0.2), color= 'black') +
  facet_grid(.~COA) +
  ylab('Performance [%]') +
  xlab('Block index') 
  # theme(panel.grid.minor.x = element_blank(), legend.position = "none")
```

```{r sensitivity analysis}
sensitivity_brm <- 
  brms::brm(dprime ~ Condition + COA + coaBlockIndex + d_nonGamer + Condition:coaBlockIndex + (1|Observer),
            data=sensitivity_per_observer,
            cores = future::availableCores())

summarize_models(sensitivity_brm)
```

## Effect of the cue-onset asynchrony (COA) and experimental condition on _response times_

```{r, group RT, cache= TRUE}
groupMedianRT <- results %>%
  group_by(Condition, COA, coaBlockIndex) %>%
  do(getvariableCI(data= ., variableOfInterest = 'RT', seed = 1538988495, avgFun = median))
```

```{r}
ggplot(data= groupMedianRT, 
       aes(x= coaBlockIndex, y= meanValue, ymin= bcaLower, ymax= bcaUpper,
           color= Condition, linetype= Condition)) + 
  geom_errorbar(width= 0.3, linetype= 'solid')+
  geom_line() +
  geom_point(aes(shape= Condition), size= 3) +
  # geom_point(position = position_jitter(width= 0.2), color= 'black') +
  facet_grid(.~COA) +
  ylab('Median RT [s]') +
  xlab('Block index') +
  theme(panel.grid.minor.x = element_blank(), legend.position = "none")

ggsave('RT.pdf', width = 12, height = 8, units = 'cm', useDingbats = FALSE)
```

```{r RT analysis}
RT <- 
  results %>%
  group_by(Observer, Condition, COA, coaBlockIndex, d_nonGamer) %>%
  summarise(MedianRT = median(RT)) %>%
  ungroup() %>%
  mutate(COA = COA / 1000)

rt_brm <- 
  brms::brm(MedianRT ~ Condition + COA + coaBlockIndex + d_nonGamer + Condition:coaBlockIndex + (1|Observer),
            data=RT,
            cores = future::availableCores())

summarize_models(rt_brm)
```

## Effect of the cue-onset asynchrony (COA) and experimental condition on _total score_
```{r, Score, cache= TRUE}
groupScore <- results %>%
  group_by(Condition, COA, coaBlockIndex) %>%
  do(getvariableCI(data= ., variableOfInterest = 'score', seed = 1538989294))
```

```{r}
ggplot(data= groupScore, 
       aes(x= coaBlockIndex, y= meanValue, ymin= bcaLower, ymax= bcaUpper,
           color= Condition, linetype= Condition)) + 
  geom_errorbar(width= 0.3, linetype= 'solid')+
  geom_line() +
  geom_point(aes(shape= Condition), size= 3) +
  # geom_point(position = position_jitter(width= 0.2), color= 'black') +
  facet_grid(.~COA) +
  ylab('Score [thousands of points]') +
  xlab('Block index') +
  theme(panel.grid.minor.x = element_blank(), legend.position = "none")
ggsave('score.pdf', width = 12, height = 8, units = 'cm', useDingbats = FALSE)
```


```{r score analysis}
score <-
  results %>%
  group_by(Observer, Condition, COA, coaBlockIndex, d_nonGamer) %>%
  summarise(BlockScore= sum(score)/1000)

score_brm <- 
  brms::brm(BlockScore ~ Condition + COA + coaBlockIndex + d_nonGamer + Condition:coaBlockIndex + (1|Observer),
            data=score %>% ungroup() %>% mutate(COA = COA / 1000),
            cores = future::availableCores())

summarize_models(score_brm)
```

## Additional analysis, for "game" condition group only

```{r position in highscore table}
hstable <- read_csv("highscore-position.csv",
                    col_types = cols(Observer = col_character(),
                                     Block = col_double(),
                                     Score = col_double(),
                                     AverageScore = col_double(),
                                     iObserver = col_double(),
                                     SessionID = col_character(),
                                     COA = col_double(),
                                     coaBlockIndex = col_double(),
                                     Condition = col_character(),
                                     IsLate = col_logical(),
                                     BlockPos = col_double(),
                                     AvgPos = col_double())) %>%
  # participants will be influenced by the previous block only
  group_by(Observer) %>%
  mutate(PrevBlockPos = lag(BlockPos),
         PrevAvgPos = lag(AvgPos)) %>%
  select(Observer, Block, PrevBlockPos, PrevAvgPos)

game <-
  results %>%
  filter(Condition == "game") %>%
  left_join(hstable, by=c("Observer", "Block")) %>%
  mutate(COA = COA / 1000)
```  

### Performance
```{r game performance}
game_accuracy <-
  game %>%
  group_by(Observer, COA, coaBlockIndex, PrevBlockPos, PrevAvgPos, d_nonGamer) %>%
  summarise(CorrectN = sum(Correct),
            TotalN = n()) %>%
  na.omit()

set.seed(8482317)
game_accuracy_brm <- brms::brm(CorrectN  | trials(TotalN) ~  coaBlockIndex + COA + d_nonGamer + PrevBlockPos + PrevAvgPos + (1|Observer),
            data=game_accuracy,
            family = "binomial",
            cores = future::availableCores())

summarize_models(game_accuracy_brm, terms = c("coaBlockIndex", "COA", "d_nonGamer", "PrevBlockPos", "PrevAvgPos"))
```

### Sensitivity

```{r game sensitivity}
game_sensitivity <-
  game %>%
  group_by(Observer, COA, coaBlockIndex, d_nonGamer, PrevBlockPos, PrevAvgPos) %>%
  summarise(n_hit = sum(Match=="match" & Response=="match"), 
            n_fa = sum(Match=="mismatch" & Response=="match"), 
            n_miss = sum(Match=="match" & Response=="mismatch"),
            n_cr = sum(Match=="mismatch" & Response=="mismatch"), 
            dprime = dprime(n_hit, n_fa, n_miss, n_cr)$dprime) %>%
  ungroup() 

set.seed(3963760)
game_sensitivy_brm <- 
  brms::brm(dprime ~  coaBlockIndex + COA + d_nonGamer + PrevBlockPos + PrevAvgPos + (1|Observer),
            data=game_sensitivity,
            control = list(max_treedepth=15),
            cores = future::availableCores())

summarize_models(game_sensitivy_brm, terms = c("PrevBlockPos", "PrevAvgPos"))
```


### Response times

```{r game RT}
game_RT <-
  game %>%
  group_by(Observer, COA, coaBlockIndex, PrevBlockPos, PrevAvgPos, d_nonGamer) %>%
  summarise(MedianRT= median(RT)) %>%
  na.omit()

set.seed(6196072)
game_rt_brm <- 
  brms::brm(MedianRT ~  coaBlockIndex + COA + d_nonGamer + PrevBlockPos + PrevAvgPos + (1|Observer),
            data=game_RT,
            control = list(max_treedepth=15),
            cores = future::availableCores())

summary(game_rt_brm)

summarize_models(game_rt_brm, terms = c("PrevBlockPos", "PrevAvgPos"))

```

```{r game RT}
game_RT <-
  game %>%
  group_by(Observer, COA, coaBlockIndex, PrevBlockPos, PrevAvgPos, d_nonGamer) %>%
  summarise(MedianRT= median(RT)) %>%
  na.omit()

set.seed(6196072)
game_rt_brm <- 
  brms::brm(MedianRT ~  coaBlockIndex + COA + d_nonGamer + PrevBlockPos + PrevAvgPos + (1|Observer),
            data=game_RT,
            control = list(max_treedepth=15),
            cores = future::availableCores())

summary(game_rt_brm)

summarize_models(game_rt_brm, terms = c("coaBlockIndex", "COA", "d_nonGamer", "PrevBlockPos", "PrevAvgPos"))

```

### Score
```{r game score}
game_score <-
  game %>%
  group_by(Observer, COA, coaBlockIndex, PrevBlockPos, PrevAvgPos, d_nonGamer) %>%
  summarise(BlockScore= sum(score)) %>%
  na.omit()

set.seed(294713)
game_score_brm <- 
  brms::brm(BlockScore ~  coaBlockIndex + COA + d_nonGamer + PrevBlockPos + PrevAvgPos + (1|Observer),
            data=game_score,
            cores = future::availableCores())

summarize_models(game_score_brm, terms = c("PrevBlockPos", "PrevAvgPos"))
```


## Mediation analysis

### Regressing each subscale on experimental group (Condition) and gaming habits (d_nonGamer)

```{r group-2-subscale}
# single average score per subscale
overall_IM <-
  qsubscale %>%
  dplyr::select(subscale, responses) %>%
  tidyr::unnest(responses) %>%
  group_by(subscale, Condition, Observer, d_nonGamer) %>%
  dplyr::summarise(AvgResponse = mean(Response))

# fitting each subscale
subscale_models <- 
  overall_IM %>%
  group_by(subscale) %>%
  tidyr::nest() %>%
  mutate(subscale_model = purrr::map(data, 
                                     ~brms::brm(AvgResponse ~ Condition + d_nonGamer,
                                                data=.,
                                                cores=future::availableCores())))

# extracting posterior of the Group/Condition -> Subscale
group2subscale <-
  subscale_models %>%
  mutate(subscale_via_condition = purrr::map(subscale_model,
                                             ~tibble(Group2Subscale=brms::posterior_samples(.)$b_Conditiongame) %>% 
                                               mutate(Iteration = 1:n()))) %>%
  select(subscale, subscale_via_condition) %>%
  tidyr::unnest(subscale_via_condition)


```

Function that computes an indirect effect and plots it
```{r compute indirect}
compute_indirect <- function(full_model){
  accuracy_mediation_full_posterior <- brms::posterior_samples(full_model)
  
  # extracting beta for individual subscales
  subscale2response <- 
    tibble(choice=full_model_posterior$b_choice,
           competence=full_model_posterior$b_competence,
           enjoyment=full_model_posterior$b_enjoyment,
           pressure=full_model_posterior$b_pressure) %>%
    mutate(Iteration = 1:n()) %>%
    tidyr::pivot_longer(cols=c("choice", "competence", "enjoyment", "pressure"), 
                        names_to = "subscale", values_to = "Subscale2Response")

  group2subscale2response <- 
   left_join(group2subscale, subscale2response, by=c("subscale", "Iteration")) %>%
    mutate(Indirect = Group2Subscale * Subscale2Response)
}

plot_indirect <- function(group2subscale2response){
  positive_indirect <-
    group2subscale2response %>%
    group_by(subscale) %>%
    summarise(AboveZero = round(100 * mean(Indirect > 0), 1),
              AboveStr = glue::glue("Above 0: {AboveZero}%"))

  ggplot(group2subscale2response, aes(x=Indirect)) +
    geom_histogram(position = "identity", bins=100) +
    geom_vline(xintercept = 0, color="white")+
    geom_text(data=positive_indirect, aes(x=-Inf, y=Inf, label=AboveStr),  
              hjust="left", vjust="top") +
    facet_grid(subscale ~ ., scales="free_y")
}

```


### Accuracy mediation

```{r accuracy mediation}
overall_accuracy <- 
  results %>%
  group_by(Observer, Condition, d_nonGamer) %>%
  summarise(CorrectN= sum(Correct),
            TotalN = n(),
            CorrectP = CorrectN/TotalN) %>%
  ungroup() %>%
  left_join(overall_IM, by=c("Condition", "Observer", "d_nonGamer"))


overall_accuracy_wide <-
  overall_accuracy %>%
  tidyr::pivot_wider(names_from = "subscale", values_from = "AvgResponse")

accuracy_mediation_full_model <- brms::brm(CorrectN  | trials(TotalN) ~ Condition + d_nonGamer + choice + competence + enjoyment + pressure,
                                           data = overall_accuracy_wide,
                                           family = "binomial",
                                           cores = future::availableCores())

accuracy_group2subscale2response <- compute_indirect(accuracy_mediation_full_model)
plot_indirect(accuracy_group2subscale2response)
```

```{r}
overall_sensitivity <-
  results %>%
  group_by(Observer, Condition, d_nonGamer) %>%
  summarise(n_hit = sum(Match=="match" & Response=="match"), 
            n_fa = sum(Match=="mismatch" & Response=="match"), 
            n_miss = sum(Match=="match" & Response=="mismatch"),
            n_cr = sum(Match=="mismatch" & Response=="mismatch"), 
            dprime = dprime(n_hit, n_fa, n_miss, n_cr)$dprime) %>%
  ungroup() %>%
  left_join(overall_IM, by=c("Condition", "Observer", "d_nonGamer"))


overall_sensitivity_wide <-
  overall_sensitivity %>%
  tidyr::pivot_wider(names_from = "subscale", values_from = "AvgResponse")

sensitivity_mediation_full_model <- brms::brm(dprime ~ Condition + d_nonGamer + choice + competence + enjoyment + pressure,
                                           data = overall_sensitivity_wide,
                                           cores = future::availableCores())

sensitivity_group2subscale2response <- compute_indirect(sensitivity_mediation_full_model)
plot_indirect(sensitivity_group2subscale2response)
```

```{r}
overall_RT <- 
  results %>%
  group_by(Observer, Condition, d_nonGamer) %>%
  summarise(MedianRT = median(RT)) %>%
  ungroup()  %>%
  left_join(overall_IM, by=c("Condition", "Observer", "d_nonGamer"))


overall_RT_wide <-
  overall_RT %>%
  tidyr::pivot_wider(names_from = "subscale", values_from = "AvgResponse")

RT_mediation_full_model <- brms::brm(MedianRT ~ Condition + d_nonGamer + choice + competence + enjoyment + pressure,
                                           data = overall_RT_wide,
                                           cores = future::availableCores())

RT_group2subscale2response <- compute_indirect(RT_mediation_full_model)
plot_indirect(RT_group2subscale2response)
```


```{r}
overall_score <-
  results %>%
  group_by(Observer, Condition, d_nonGamer) %>%
  summarise(TotalScore= sum(score)/1000) %>%
  ungroup()  %>%
  left_join(overall_IM, by=c("Condition", "Observer", "d_nonGamer"))


overall_score_wide <-
  overall_score %>%
  tidyr::pivot_wider(names_from = "subscale", values_from = "AvgResponse")

score_mediation_full_model <- brms::brm(TotalScore ~ Condition + d_nonGamer + choice + competence + enjoyment + pressure,
                                           data = overall_score_wide,
                                           cores = future::availableCores())

score_group2subscale2response <- compute_indirect(score_mediation_full_model)
plot_indirect(score_group2subscale2response)
```

```{r indirect effect summary}
all_group2subscale2response <-
  bind_rows(accuracy_group2subscale2response %>% mutate(Measure = "Accuracy"),
            sensitivity_group2subscale2response %>% mutate(Measure = "Sensitivity"),
            RT_group2subscale2response %>% mutate(Measure = "RT"),
            score_group2subscale2response %>% mutate(Measure = "Score"))


all_group2subscale2response %>%
  group_by(Measure, subscale) %>%
  summarise(Median = median(Indirect),
            LowerCI = quantile(Indirect, 0.025),
            UpperCI = quantile(Indirect, 0.975)) %>%
  mutate_if(is.numeric, round, digits=2) %>%
  mutate(Info = glue::glue("{LowerCI}|{Median}|{UpperCI}")) %>%
  select(-Median, -LowerCI,, -UpperCI) %>%
  tidyr::pivot_wider(names_from = subscale, values_from = Info) 
  
  

```
